# 興味関心メモ: 2026-02-10

## 1. AIは仕事を激化させる — 生産性パラドックスに学術的エビデンス

はてブ「エンジニアは、なぜ生成AIで仕事が楽にならないのか」(513 users)が2日連続でトップ圏。Simon Willisonが紹介したBerkeley Haas研究が同じ結論を裏付けた。**複数ソースが同時に同じテーマを語っており、トレンド確信度が極めて高い**。

### Berkeley Haas研究の要点（Simon Willison, #25）
- 米テック企業200名の従業員を2025年4-12月に追跡調査（HBR掲載）
- AI導入後、**並列作業が常態化**: 手動コーディングしながらAIに別バージョンを生成させ、複数エージェントを同時実行し、先送りタスクを復活させる
- 結果: **生産的に感じるが、注意の切り替え・AI出力のチェック・タスク数の増加で認知負荷が激増**
- 「常にジャグリングしている感覚」
- Simon Willison自身も「複数プロジェクトを並行すると数時間で精神エネルギーが枯渇」「もう1プロンプトだけ、の誘惑で睡眠を失う人も」と共感

### Deep Work思想との接続（02/09からの継続）
- 02/09: 「AIが簡単な部分を楽にし、難しい部分をより難しくする」(HN 238pt)
- 02/10: Berkeley Haas研究が**200名のデータで実証** — 感覚的な議論から学術的エビデンスへ
- **根本的な問題**: AIが生産性を上げるのではなく、**仕事の強度（intensity）を上げている**
- HBR提言: 組織は「AI実践」の構造化が必要。燃え尽きを防ぎ、真の生産性向上と持続不可能な強度を区別すべき
- **自分へのアクション**: AI並列作業の誘惑に抗い、シングルタスク × Deep Workを意識的に維持する

---

## 2. エージェント向け言語設計 — Armin Ronacherの提案

Flask/Rye作者のArmin Ronacherが「A Language for Agents」(#17, 21 users)を投稿。AIエージェントのためのプログラミング言語設計を提案。HNでも「非同期エージェントを定義できる人はほぼいない」(#19, 17pt)が同時に話題。

### 核心的な主張
- **「コーディングのコストが劇的に下がった今、エコシステムの広さは問題にならない」** — エージェントが必要に応じて言語間でポートできるため、既存言語のネットワーク効果が弱まっている
- **人間向けに最適化された言語はエージェントを阻害する**: 重い型推論、空白依存の構文、暗黙のコンテキストがLLMのパフォーマンスを下げる

### 技術的提案（6つ）
1. **構文 > ツーリング**: LSP有無で体験が分裂しない言語。エージェントは完全な環境なしでスニペットを操作する
2. **明示的デリミタ**: インデントベースもブラケット多重ネストもLLMを混乱させる。明示的な構造が一貫性を向上
3. **エフェクトマーカー**: 関数が「時刻」「乱数」「DB接続」等の依存を明示宣言。テストモック化が精密に
4. **型付き結果**: 例外の代わりに明示的エラー型。エージェントのエラーハンドリング不確実性を低減
5. **Greppableなコード**: Goの `context.Context` のようにパッケージプレフィックスを必須化。IDE不要でローカル理解可能
6. **統一ビルドシステム**: シンプルで決定論的なコンパイル

### 「非同期エージェントを定義できる人はほぼいない」(#19)との接続
- HNで同日に議論。エージェントの定義自体が曖昧なまま、エコシステムが爆発的に成長している
- Ronacherの提案は「エージェントが使いやすい言語」レベルから根本解決を試みる、より本質的なアプローチ
- **Claude Code Agent Teams文脈**: Agent Teamsの各メンバーが操作するコードが「エージェントフレンドリー」であれば効率が上がるはず

---

## 3. Claude Codeエコシステムの爆発 — 9,000プラグイン時代

「Claude Codeを最強にするプラグイン・MCP・ツール総まとめ」(#14, 39 users)が、現在のエコシステム全体像を俯瞰。02/09の「拡張機能の整理」(224 users)と合わせて、Claude Codeの拡張レイヤーが急速に成熟。

### 必須級MCPサーバー
- **GitHub MCP**: PR/Issue/CI/CD操作
- **Context7 MCP**: 最新APIドキュメント自動注入 → コード生成精度向上
- **Playwright MCP**: E2Eテスト自動化 + スクリーンショット（r/ClaudeCodeの #40 「Claude Code + Playwright = スーパーパワー」97 upsと一致）
- **Sentry MCP**: エラー監視 → スタックトレースから修正コード生成

### 注目プラグイン
- **Claude-Mem**（GitHub ★20,000超）: セッション間コンテキスト消失問題を解決。自動キャプチャ + 段階的検索でトークン効率10倍
- **Superpowers**（★43,000超）: 「計画→テスト→実装」の構造化フロー強制
- **Ralph Wiggum Loop**: タスク完了まで自律反復。YC界隈で定番化

### 2026年のトレンド
1. **メモリ基盤の重要性** — Claude-Memの成長。02/09のAuto-Memory機能解説(79 ups)と同じ方向
2. **構造化ワークフロー** — Superpowersがvibe codingの無秩序さを矯正
3. **自律反復ループ** — エージェントが完了まで自律的に動く設計
4. **業種特化プラグイン** — コーディング外への拡大

### 自分のセットアップへの示唆
- 現在のskills構成（neta-trend-daily, neta-interest-daily, git-push）に加えて、Context7 MCP + Playwright MCPの導入を検討する価値あり

---

## 4. LLMでソート — 古典CSとLLMの融合

「LLMでソート」(#9, 129 users)は、LLMを比較関数としてソートアルゴリズムに組み込む手法の解説。学術的でありながら実用的。

### コアアイデア
- `functools.cmp_to_key()` でLLMを比較器として使用
- 数値比較ではなく**「どちらが好みか」「どちらがクエリに関連するか」**という主観的基準でソート可能に

### 実験結果
- **論文ソート**: ICLR 2026のオーラル論文を「著者の好み」でランク付け → 価値観に合致した論文が上位に
- **ニュースソート**: 295件の経済ニュースを「楽観的〜悲観的」でソート。2,324回の比較、約2.5分、$0.85

### 技術的ポイント
- **推移性の問題**: LLMは A>B, B>C なら A>C を保証しない → **KwikSort**アルゴリズムで対処
- **位置バイアス**: 順序を逆にした両方向比較で緩和
- 実用推奨: スライディングウィンドウ法 or KwikSort

### 応用可能性
- **トレンド収集の文脈**: 自分の興味領域に基づいて記事を自動ランキングする仕組みに応用できる
- 現在の★★★/★★/★は手動的な評価だが、LLMソートで「自分の過去の興味パターン」に基づく自動ランキングが理論上可能
- RAG + LLMソートで「自分にとって最も関連性の高い記事」を定量的に順位付けできる

---

## 5. AWS Bedrock — Opus 4.6対応とエージェント基盤の週次まとめ

#22 Claude Opus 4.6 Bedrock対応は02/08-09からの継続だが、1週間のBedrock関連アップデートを俯瞰すると、エージェント基盤としての方向性が明確。

### 今週のBedrock AI/ML関連（3連続発表）
- **Claude Opus 4.6対応** (02/05) — 最新・最強モデルが即座にマネージド利用可能
- **構造化出力** (02/04) — JSON Schema準拠の出力制御。LLMアプリの安定性に直結
- **AgentCore Browserプロファイル** (02/06) — エージェントのブラウザ操作にプロファイル管理

### 02/09のinterestメモとの接続
- 3日連続でBedrock AI/MLアップデートを追跡中
- **Bedrock AgentCore + Claude Code Agent Teams**の組み合わせが、クラウド上マルチエージェントの現実的な道筋
- ローカルのAgent Teams（ファイルシステム協調）vs クラウドのAgentCore（マネージドサービス）という二層構造が見えてきた

---

## 6. ローカルLLM新展開 — GLM 5登場とローカル勢への逆風

r/LocalLLaMAで「ローカル勢への悪いニュース」(#35, 371 ups, 200 comments)が大激論。一方でGLM 5のリリース(#37, 198 ups / #38, 118 ups)とQwen3 Coder Nextの汎用性評価(#36, 266 ups)がポジティブ。

### ローカルLLMの逆風（200コメントの議論）
- 371 ups + 200 commentsは相当な反響。詳細要確認だが、コスト・電力・性能ギャップに関する議論か
- 02/09のinterestメモ「Qwen3.5マージ、Coder Next実用化」のポジティブトーンとは対照的

### GLM 5の登場
- vllmのPRで発見 → Transformersサポートも進行中
- DeepSeek V4、Qwen 3.5、MiniMax 2.2と合わせて**中国発OSSモデルの競争が激化**
- 02/09のQwen3.5 llama.cppマージに続き、OSS LLMエコシステムの進化が加速

### Qwen3 Coder Next = 汎用モデル（266 ups, 87 comments）
- 「Coderという名前に騙されるな、そのサイズ最高の汎用モデル」
- 02/09の「60GB以下で使えるコーディングモデル」(314 ups)からさらに評価が上昇
- **コーディング特化ではなく汎用性能が高い**ことが判明 → ローカルLLMの万能選手として定着しつつある
